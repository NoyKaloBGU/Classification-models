{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold,RepeatedStratifiedKFold, cross_val_score, cross_validate\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import  accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, CategoricalNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.feature_selection import RFE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt  \n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.feature_selection import SelectKBest, chi2,f_classif\n",
    "from sklearn import preprocessing\n",
    "import math\n",
    "from sklearn.metrics import fbeta_score\n",
    "from numpy import arange\n",
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_to_optimize = 'MCC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "simplefilter(action='ignore', category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_and_summarize_best_model(results,ml_results,best_models):\n",
    "    ml_results = pd.concat([ml_results, results],sort=True)\n",
    "    best_model_index = np.argmax(np.array(results[metric_to_optimize]))\n",
    "    best_model = results.iloc[best_model_index]\n",
    "    best_models = pd.concat([best_models, pd.DataFrame(best_model).transpose()],sort = True)\n",
    "    \n",
    "    return ml_results,best_models,best_model_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_metrics():\n",
    "    '''\n",
    "    initialize the (empty) metrics structures\n",
    "    :return: metrics_results\n",
    "    '''\n",
    "    metrics_results = {'FNR': None, 'FPR': None, 'MCC':None, 'ACC': None, 'F1score': None,'F2score': None}\n",
    "    metrics_results['FNR'] = {'DT':None,'SVM':None,'RF':None,'NB': None,'KNN':None,'LogisticRegression':None}\n",
    "    metrics_results['FPR'] = {'DT':None,'SVM':None,'RF':None,'NB': None,'KNN':None,'LogisticRegression':None}\n",
    "    metrics_results['MCC'] = {'DT':None,'SVM':None,'RF':None,'NB': None,'KNN':None,'LogisticRegression':None}\n",
    "    metrics_results['ACC'] = {'DT':None,'SVM':None,'RF':None,'NB': None,'KNN':None,'LogisticRegression':None}\n",
    "    metrics_results['F1score'] = {'DT':None,'SVM':None,'RF':None,'NB': None,'KNN':None,'LogisticRegression':None}\n",
    "    metrics_results['F2score'] = {'DT':None,'SVM':None,'RF':None,'NB': None,'KNN':None,'LogisticRegression':None}\n",
    "    return metrics_results\n",
    "\n",
    "def init_best_models():\n",
    "    best_models = pd.DataFrame(columns=['Algorithm','model_index', 'parameters',\n",
    "                                               'FNR','FPR','MCC','ACC','F1score','F2score'])\n",
    "    return best_models\n",
    "\n",
    "def init_ml_results():\n",
    "    ml_results = pd.DataFrame(columns=['Algorithm','model_index', 'parameters',\n",
    "                                               'FNR','FPR','MCC','ACC','F1score','F2score'])\n",
    "    return ml_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_calculation_as_binary(all_y,all_predictions):\n",
    "    cm = confusion_matrix(all_y,all_predictions,labels = ['Clog','Control','Leak'])\n",
    "    TP = cm[0,0]+cm[0,2]+cm[2,2]+cm[2,0] # clog or leak classified correctly\n",
    "    FN = cm[0,1]+cm[2,1] #clog or leak classified as control\n",
    "    FP = cm[1,0]+cm[1,2] #control classified as leak or clog\n",
    "    TN = cm[1,1] #control  classified correctly\n",
    "    \n",
    "    FNR = FN/(FN+TP)\n",
    "    FPR = FP/(FP+TN)\n",
    "\n",
    "    Recall =TP/(TP+FN)\n",
    "    Precision=TP/(TP+FP)\n",
    "#     Accuracybinary = (TP+TN)/(TP+TN+FN+FP)\n",
    "    F1_Binary = 2*(Recall*Precision)/(Recall+Precision)\n",
    "    F2_Binary = ((1 + 2**2) * Precision * Recall) / (2**2 * Precision + Recall)\n",
    "    return FNR,FPR,F1_Binary,F2_Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(classifier_name,y_test,y_prediction_old,metrics_results):\n",
    "    '''\n",
    "    calculate each metric for evaluation\n",
    "    :param classifier_name: name of classifier used (svm, NB, etc)\n",
    "    :param y_test:\n",
    "    :param y_prediction:\n",
    "    :param metrics_results:\n",
    "    :return:\n",
    "    '''\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.metrics import classification_report\n",
    "\n",
    "    from sklearn.metrics import matthews_corrcoef\n",
    "    y_test = y_test.astype('category').to_numpy()\n",
    "    y_prediction = np.copy(y_prediction_old)\n",
    "    y_prediction[(y_test == 'Clog') & (y_prediction_old==\"Leak\")]='Clog' #CLOG CLASIFIED AS LEAK\n",
    "    y_prediction[(y_test == 'Leak') & (y_prediction_old==\"Clog\")]='Leak'# LEAK CLASSIFIED AS CLOG\n",
    "    \n",
    "    cnf_matrix = confusion_matrix(y_test, y_prediction,\n",
    "                                         labels=[\"Leak\", \"Clog\", \"Control\"])\n",
    "#     import seaborn as sns\n",
    "#     plt.figure()\n",
    "#     sns.heatmap(cnf_matrix, annot=True)\n",
    "    FP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix)  \n",
    "    FN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\n",
    "\n",
    "    TP = np.diag(cnf_matrix)\n",
    "    TN = cnf_matrix.sum() - (FP + FN + TP)\n",
    "\n",
    "    FP = FP.astype(float)\n",
    "    FN = FN.astype(float)\n",
    "    TP = TP.astype(float)\n",
    "    TN = TN.astype(float)\n",
    "\n",
    "    # Fall out or false positive rate\n",
    "    FPR_mal = (FP/(FP+TN))\n",
    "\n",
    "    # False negative rate\n",
    "    FNR_mal = (FN/(TP+FN))\n",
    "\n",
    "    y_prediction_binary = np.zeros(y_test.size)\n",
    "    y_prediction_binary[(y_prediction_old==\"Clog\") | (y_prediction_old==\"Leak\")]=1 #CLOG CLASIFIED AS LEAK\n",
    "    y_prediction_binary[y_prediction_old == \"Control\"]=0\n",
    "    \n",
    "    y_test_binary =np.zeros(y_test.size)\n",
    "    y_test_binary[(y_test == \"Clog\")| (y_test==\"Leak\")]=1\n",
    "    y_test_binary[y_test == \"Control\"]=0\n",
    "    \n",
    "\n",
    "    TN, FP, FN, TP = confusion_matrix(y_test_binary, y_prediction_binary).ravel()\n",
    "\n",
    "    FPR  = FP / (FP + TN)\n",
    "    FNR = FN / (FN + TP)\n",
    "\n",
    "    F1_Binary = fbeta_score(y_test_binary, y_prediction_binary, beta=1)\n",
    "    F2_Binary = fbeta_score(y_test_binary, y_prediction_binary, beta=2)\n",
    "    MCC = matthews_corrcoef(y_test_binary, y_prediction_binary)\n",
    "    Accuracy = accuracy_score(y_test_binary, y_prediction_binary)\n",
    "    balanced_ACC = balanced_accuracy_score(y_test_binary, y_prediction_binary)\n",
    "    \n",
    "#     FNR,FPR,F1_Binary,F2_Binary = metrics_calculation_as_binary(y_test, y_prediction)#As Binary\n",
    "    \n",
    "    MCC_multiclass = matthews_corrcoef(y_test, y_prediction)\n",
    "#     Accuracy = accuracy_score(y_test, y_prediction)\n",
    "    metrics_results['FNR'][classifier_name] = {'FNR':FNR,'Leak':FNR_mal[0],'Clog':FNR_mal[1],'MCC_multiclass':MCC_multiclass}\n",
    "    metrics_results['FPR'][classifier_name] = {'FPR':FPR,'Leak':FPR_mal[0],'Clog':FPR_mal[1],'balanced_ACC':balanced_ACC}\n",
    "    metrics_results['MCC'][classifier_name] = MCC\n",
    "    metrics_results['ACC'][classifier_name] = Accuracy\n",
    "    metrics_results['F1score'][classifier_name] = F1_Binary\n",
    "    metrics_results['F2score'][classifier_name] = F2_Binary\n",
    "    return metrics_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_folds_for_best_model(model_index,folds,MCC_results,F1score_results,F2score_results,FNR_results):\n",
    "    print(model_index)\n",
    "    folder_path = 'C:\\\\Users\\\\noy\\\\Desktop\\\\תזה\\\\Results\\\\Kedma_secend_best_model_'\n",
    "    balanced_ACC_results = pd.DataFrame(d['balanced_ACC'] for d in FNR_results).values.ravel()\n",
    "    Al = 'KNN_73_multiclass'\n",
    "\n",
    "    best_mudel_res= pd.DataFrame(data={'Algorithm':Al,\n",
    "                                          'Fold_number':folds,\n",
    "                                          'MCC': MCC_results,\n",
    "                                           'balanced_ACC':balanced_ACC_results,\n",
    "                                          'F1score': F1score_results,\n",
    "                                          'F2score': F2score_results})\n",
    "    best_mudel_res =best_mudel_res.set_index('Fold_number')\n",
    "    best_mudel_res.to_csv(folder_path+Al+'_folds_results.csv')\n",
    "    print('Created')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV_model_tunning(data,data_labels,classifier,Algorithm,model_index,metrics_results,results_summary,params):\n",
    "    folds,FNR_results, FPR_results, MCC_results, ACC_results,F1score_results,F2score_results = [],[],[],[],[],[],[]                      \n",
    "    if(model_index==73):\n",
    "        random.seed(10)\n",
    "        fold=1\n",
    "        skf = RepeatedStratifiedKFold(n_splits=5,n_repeats=5, random_state=12)\n",
    "        # K_folds:\n",
    "        for train_index, test_index in skf.split(data, data_labels):\n",
    "            x_train_fold, x_test_fold = data.iloc[train_index], data.iloc[test_index]\n",
    "            y_train_fold, y_test_fold = data_labels.iloc[train_index], data_labels.iloc[test_index]\n",
    "            if (Algorithm not in ['RF','DT']):\n",
    "                if (Algorithm in('Naive Bayes','svm_linear')):\n",
    "                    scaler = MinMaxScaler()\n",
    "                else:\n",
    "                    scaler = StandardScaler()\n",
    "                x_train_fold = scaler.fit_transform(x_train_fold)\n",
    "                x_test_fold = scaler.fit_transform(x_test_fold)\n",
    "            classifier.fit(x_train_fold, y_train_fold.values.ravel())\n",
    "            y_prediction = classifier.predict(x_test_fold)\n",
    "            metrics_results = calculate_metrics(Algorithm,y_test_fold,y_prediction,metrics_results)\n",
    "            FNR_results.append(metrics_results['FNR'][Algorithm])\n",
    "            FPR_results.append(metrics_results['FPR'][Algorithm])\n",
    "            MCC_results.append(metrics_results['MCC'][Algorithm])\n",
    "            ACC_results.append(metrics_results['ACC'][Algorithm])\n",
    "            F1score_results.append(metrics_results['F1score'][Algorithm])\n",
    "            F2score_results.append(metrics_results['F2score'][Algorithm])\n",
    "            folds.append(fold)\n",
    "            fold =fold+1\n",
    "        save_folds_for_best_model(model_index,folds,MCC_results,F1score_results,F2score_results,FPR_results)\n",
    "\n",
    "        results_summary = results_summary.append({'Algorithm':Algorithm,\n",
    "                                                  'model_index':model_index,\n",
    "                                                  'parameters':params,\n",
    "                                                  'FNR': {'FNR':sum(d['FNR'] for d in FNR_results) / len(FNR_results),\n",
    "                                                         'FNR_Leak':sum(d['Leak'] for d in FNR_results) / len(FNR_results),\n",
    "                                                         'FNR_Clog':sum(d['Clog'] for d in FNR_results) / len(FNR_results),\n",
    "                                                         'MCC_multiclass':sum(d['MCC_multiclass'] for d in FNR_results) / len(FNR_results)}, #np.mean(FNR_results),\n",
    "                                                  'FPR': {'FPR':sum(d['FPR'] for d in FPR_results) / len(FPR_results),\n",
    "                                                         'FPR_Leak':sum(d['Leak'] for d in FPR_results) / len(FPR_results),\n",
    "                                                         'FPR_Clog':sum(d['Clog'] for d in FPR_results) / len(FPR_results),\n",
    "                                                          'balanced_ACC':sum(d['balanced_ACC'] for d in FPR_results) / len(FPR_results)},\n",
    "                                                  'MCC': np.mean(MCC_results),\n",
    "                                                  'ACC': np.mean(ACC_results),\n",
    "                                                  'F1score': np.mean(F1score_results),\n",
    "                                                  'F2score': np.mean(F2score_results)},\n",
    "                                                 ignore_index=True)\n",
    "    return results_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_CV_RandomForest(folder_path_results,data,data_labels,metrics_results,best_models, ml_results):\n",
    "    model_index = int(1)\n",
    "    results_summary = pd.DataFrame(columns=['Algorithm','model_index', 'parameters',\n",
    "                                               'FNR','FPR','MCC','ACC','F1score','F2score'])\n",
    "    Algorithm = 'RF' \n",
    "    \n",
    "    n_estimators = [200, 500]               # number of trees in the foreset\n",
    "    max_depth = [5, 8, 10, 20]              # max number of levels in each decision tree\n",
    "    criterion = ['gini', 'entropy']\n",
    "    min_samples_split = [2, 5, 10, 15,20]   # min number of data points placed in a node before the node is split, used to control over-fitting\n",
    "    bootstrap = [True, False]\n",
    "    for n in n_estimators:\n",
    "        for max in max_depth:\n",
    "            for c in criterion:\n",
    "                for min_sample in min_samples_split:\n",
    "                    for b in bootstrap:\n",
    "                        classifier = RandomForestClassifier(random_state=12,class_weight='balanced', n_estimators=n,\n",
    "                                                            max_depth=max, criterion=c,min_samples_split=min_sample,bootstrap=b)  # class_weight: misclassifying the rare class is punished harsher.\n",
    "                        params = {\"n_estimators\": n,\"criterion\": c,\"min_samples_split\":min_sample,\"bootstrap\":b,'max_depth':max}\n",
    "                        results_summary = CV_model_tunning(data,data_labels,classifier,Algorithm,model_index,metrics_results,results_summary,params)\n",
    "                        model_index+=1\n",
    "    print(Algorithm,'_results_summary was created')\n",
    "    results_summary.to_csv(folder_path_results+'\\\\'+Algorithm+'_results_summary.csv')\n",
    "    ml_results,best_models,best_model_index = print_and_summarize_best_model(results_summary,ml_results,best_models)\n",
    "    return ml_results,best_models,metrics_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_CV_svm_linear(folder_path_results,data,data_labels,metrics_results,best_models, ml_results):\n",
    "    model_index = int(1)\n",
    "    results_summary = pd.DataFrame(columns=['Algorithm','model_index', 'parameters',\n",
    "                                               'FNR','FPR','MCC','ACC','F1score','F2score'])\n",
    "    Algorithm = 'svm_linear'\n",
    "    kernel = 'linear'\n",
    "    cs = [0.1, 1, 10, 100]\n",
    "    for c in cs:\n",
    "        classifier = svm.SVC(probability=True,kernel=kernel,C=c,max_iter=100000)\n",
    "        params = {\"kernel\": kernel,\"C\": c}\n",
    "        results_summary = CV_model_tunning(data,data_labels,classifier,Algorithm,model_index,metrics_results,results_summary,params)\n",
    "        model_index+=1\n",
    "\n",
    "    print(Algorithm,'_results_summary was created')\n",
    "    results_summary.to_csv(folder_path_results+'\\\\'+Algorithm+'_results_summary.csv')\n",
    "    ml_results,best_models,best_model_index = print_and_summarize_best_model(results_summary,ml_results,best_models)\n",
    "    return ml_results,best_models,metrics_results   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_CV_svm_rbf(folder_path_results,data,data_labels,metrics_results,best_models, ml_results):\n",
    "    \n",
    "    model_index = int(1)\n",
    "    results_summary = pd.DataFrame(columns=['Algorithm','model_index', 'parameters',\n",
    "                                               'FNR','FPR','MCC','ACC','F1score','F2score'])\n",
    "    Algorithm = 'svm_rbf'\n",
    "    kernel =  'rbf'\n",
    "    cs = [0.1, 1, 10, 100]\n",
    "    gammas = [0.0001, 0.001, 0.01, 0.1, 1, 2, 3, 4]\n",
    "    for c in cs:\n",
    "        for gamma in gammas:\n",
    "            classifier = svm.SVC(probability=True,kernel=kernel,C=c,gamma=gamma,max_iter=100000)\n",
    "            params = {\"kernel\": kernel,\"C\": c,'gamma':gamma}\n",
    "            results_summary = CV_model_tunning(data,data_labels,classifier,Algorithm,model_index,metrics_results,results_summary,params)\n",
    "\n",
    "            model_index+=1\n",
    "    print(Algorithm,'_results_summary was created')\n",
    "    results_summary.to_csv(folder_path_results+'\\\\'+Algorithm+'_results_summary.csv')\n",
    "    ml_results,best_models,best_model_index = print_and_summarize_best_model(results_summary,ml_results,best_models)\n",
    "    return ml_results,best_models,metrics_results   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_CV_svm_poly(folder_path_results,data,data_labels,metrics_results,best_models, ml_results):\n",
    "    model_index = int(1)\n",
    "    results_summary = pd.DataFrame(columns=['Algorithm','model_index', 'parameters',\n",
    "                                               'FNR','FPR','MCC','ACC','F1score','F2score'])\n",
    "    Algorithm = 'svm_poly'\n",
    "\n",
    "    kernel = 'poly'\n",
    "    cs = [0.1, 1, 10, 100]\n",
    "    gammas = [0.0001, 0.001, 0.01, 0.1, 1]\n",
    "    degrees = [2,3,4,5]\n",
    "    for c in cs:\n",
    "        for gamma in gammas:\n",
    "            for degree in degrees:\n",
    "                classifier = svm.SVC(probability=True,kernel=kernel,C=c,gamma=gamma,degree=degree,max_iter=100000)\n",
    "                params = {\"kernel\": kernel,\"C\": c,'gamma':gamma,'degree':degree}\n",
    "                results_summary = CV_model_tunning(data,data_labels,classifier,Algorithm,model_index,metrics_results,results_summary,params)\n",
    "\n",
    "                model_index+=1\n",
    "    print(Algorithm,'_results_summary was created')\n",
    "    results_summary.to_csv(folder_path_results+'\\\\'+Algorithm+'_results_summary.csv')\n",
    "    ml_results,best_models,best_model_index = print_and_summarize_best_model(results_summary,ml_results,best_models)\n",
    "    return ml_results,best_models,metrics_results   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_CV_DecisionTree(folder_path_results,data,data_labels,metrics_results,best_models, ml_results):\n",
    "    model_index = int(1)\n",
    "    results_summary = pd.DataFrame(columns=['Algorithm','model_index', 'parameters',\n",
    "                                               'FNR','FPR','MCC','ACC','F1score','F2score'])\n",
    "    Algorithm = 'DT'\n",
    "    \n",
    "    criterion = [\"gini\", \"entropy\"]\n",
    "    splitter = [\"best\", \"random\"]\n",
    "    min_samples_split = [2, 5, 10, 15,20]  # min number of data points placed in a node before the node is split, used to control over-fitting\n",
    "    for c in criterion:\n",
    "        for s in splitter:\n",
    "            for min_split in min_samples_split:\n",
    "                classifier = tree.DecisionTreeClassifier(criterion=c,splitter=s,min_samples_split=min_split)\n",
    "                params = {\"criterion\": c,\"splitter\": s,'min_samples_split':min_split}\n",
    "                results_summary = CV_model_tunning(data,data_labels,classifier,Algorithm,model_index,metrics_results,results_summary,params)\n",
    "\n",
    "                model_index+=1\n",
    "    print(Algorithm,'_results_summary was created')\n",
    "    results_summary.to_csv(folder_path_results+'\\\\'+Algorithm+'_results_summary.csv')\n",
    "    ml_results,best_models,best_model_index = print_and_summarize_best_model(results_summary,ml_results,best_models)\n",
    "    return ml_results,best_models,metrics_results   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_CV_NaiveBayes(folder_path_results,data,data_labels,metrics_results,best_models, ml_results):\n",
    "    model_index = int(1)\n",
    "    results_summary = pd.DataFrame(columns=['Algorithm','model_index', 'parameters',\n",
    "                                               'FNR','FPR','MCC','ACC','F1score','F2score'])\n",
    "    Algorithm = 'NB'\n",
    "    Algorithm = 'Naive Bayes'\n",
    "    NB_Classifiers = [GaussianNB(), MultinomialNB()]\n",
    "    # CategoricalNB()\n",
    "    for NB_clf in NB_Classifiers:\n",
    "        classifier = NB_clf  # create classifier\n",
    "        params = {\"NB_Classifiers\": NB_clf}\n",
    "        results_summary = CV_model_tunning(data,data_labels,classifier,Algorithm,model_index,metrics_results,results_summary,params)\n",
    "\n",
    "        model_index+=1\n",
    "    print(Algorithm,'_results_summary was created')\n",
    "    results_summary.to_csv(folder_path_results+'\\\\'+Algorithm+'_results_summary.csv')\n",
    "    ml_results,best_models,best_model_index = print_and_summarize_best_model(results_summary,ml_results,best_models)\n",
    "    return ml_results,best_models,metrics_results   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_CV_KNN(folder_path_results,data,data_labels,metrics_results,best_models, ml_results):\n",
    "    model_index = int(1)\n",
    "    results_summary = pd.DataFrame(columns=['Algorithm','model_index', 'parameters',\n",
    "                                               'FNR','FPR','MCC','ACC','F1score','F2score'])\n",
    "    Algorithm = 'KNN'\n",
    "    n_neighbors = range(1, 11)\n",
    "    weights = ['uniform', 'distance']\n",
    "    Algorithms = ['auto', 'ball_tree', 'kd_tree', 'brute']  # Algorithm used to compute the nearest neighbors\n",
    "    for n in n_neighbors:\n",
    "        for w in weights:\n",
    "            for alg in Algorithms:\n",
    "                classifier = KNeighborsClassifier(n_neighbors=n,weights=w,algorithm=alg)  # create classifier\n",
    "                params = {\"n_neighbors\": n,'weights':w,\"Algorithm\":alg}\n",
    "                results_summary = CV_model_tunning(data,data_labels,classifier,Algorithm,model_index,metrics_results,results_summary,params)\n",
    "\n",
    "                model_index+=1\n",
    "    print(Algorithm,'_results_summary was created')\n",
    "    results_summary.to_csv(folder_path_results+'\\\\'+Algorithm+'_results_summary.csv')\n",
    "    ml_results,best_models,best_model_index = print_and_summarize_best_model(results_summary,ml_results,best_models)\n",
    "    return ml_results,best_models,metrics_results  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conduct_tunning_and_classification_for_each_family_model_CV(data,data_labels,stage):\n",
    "    best_models = init_best_models()\n",
    "    ml_results = init_ml_results()\n",
    "    metrics_results = init_metrics()\n",
    "    folder_path = 'C:\\\\Users\\\\noy\\\\Desktop\\\\תזה\\\\Results\\\\Multiclass_calssification\\\\Kedma'+stage\n",
    "    folder_path_results = folder_path+'\\\\classifiers'\n",
    "#     print('DecisionTree')\n",
    "#     ml_results,best_models,metrics_results = train_test_CV_DecisionTree(folder_path_results,data,data_labels,metrics_results,best_models, ml_results)\n",
    "#     print('RandomForest')\n",
    "#     ml_results,best_models,metrics_results = train_test_CV_RandomForest(folder_path_results,data,data_labels,metrics_results,best_models, ml_results)\n",
    "#     print('NaiveBayes')\n",
    "#     ml_results,best_models,metrics_results = train_test_CV_NaiveBayes(folder_path_results,data,data_labels,metrics_results,best_models, ml_results)\n",
    "    print('KNN')\n",
    "    ml_results,best_models,metrics_results = train_test_CV_KNN(folder_path_results,data,data_labels,metrics_results,best_models, ml_results)\n",
    "#     print('svm_linear')\n",
    "#     ml_results,best_models,metrics_results = train_test_CV_svm_linear(folder_path_results,data,data_labels,metrics_results,best_models, ml_results)\n",
    "#     print('svm_rbf')\n",
    "#     ml_results,best_models,metrics_results = train_test_CV_svm_rbf(folder_path_results,data,data_labels,metrics_results,best_models, ml_results)\n",
    "#     print('svm_poly')\n",
    "#     ml_results,best_models,metrics_results = train_test_CV_svm_poly(folder_path_results,data,data_labels,metrics_results,best_models, ml_results)\n",
    "   \n",
    "    best_models = pd.concat([best_models.drop(['FNR','FPR'], axis=1),\n",
    "               best_models['FNR'].apply(pd.Series),\n",
    "               best_models['FPR'].apply(pd.Series)], axis=1)\n",
    "    ml_results = pd.concat([ml_results.drop(['FNR','FPR'], axis=1),\n",
    "               ml_results['FNR'].apply(pd.Series),\n",
    "               ml_results['FPR'].apply(pd.Series)], axis=1)\n",
    "   \n",
    "    best_models = best_models.reindex(columns=['Algorithm',\n",
    "                                               'model_index',\n",
    "                                               'MCC',\n",
    "                                               'ACC',\n",
    "                                              'F1score',\n",
    "                                              'F2score',\n",
    "                                              'FNR',\n",
    "                                              'FPR',\n",
    "                                              'FNR_Leak',\n",
    "                                              'FNR_Clog',\n",
    "                                              'FPR_Leak',\n",
    "                                              'FPR_Clog',\n",
    "                                               'balanced_ACC',\n",
    "                                              'MCC_multiclass']).reset_index().drop(['index'],axis=1)\n",
    "    \n",
    "    best_models.iloc[:,2:] = best_models.iloc[:,2:].round(5)\n",
    "    best_models =best_models.set_index('Algorithm')\n",
    "    best_models=best_models.T\n",
    "    ml_results = ml_results.sort_values(by=[metric_to_optimize],ascending = False)\n",
    "\n",
    "#     best_models.to_csv(folder_path+'\\\\best_models_include_malf_metrics.csv')\n",
    "#     ml_results.to_csv(folder_path+'\\\\ml_results_include_malf_metrics.csv')\n",
    "    return ml_results,best_models,metrics_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RFECV_Random_Forest(X,y):\n",
    "    from numpy import mean\n",
    "    from numpy import std\n",
    "    from sklearn.datasets import make_classification\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "    from sklearn.feature_selection import RFECV\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.metrics import matthews_corrcoef\n",
    "    import sklearn.metrics as m\n",
    "    from sklearn.metrics import fbeta_score, make_scorer\n",
    "    ftwo_scorer = make_scorer(fbeta_score, beta=2, average='weighted')\n",
    "\n",
    "    average='weighted'\n",
    "    # Automatically select the number of features for RFE\n",
    "    # create pipeline\n",
    "    rfe = RFECV(estimator=RandomForestClassifier())\n",
    "\n",
    "    model = RandomForestClassifier()\n",
    "    pipeline = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "    # evaluate model\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5,n_repeats=5, random_state=12)\n",
    "    \n",
    "    n_scores = cross_val_score(pipeline, X, y, scoring=ftwo_scorer, cv=cv, n_jobs=-1, error_score='raise')\n",
    "    # report performance\n",
    "    print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "    rfe.fit(X, y)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Number of features selected\")\n",
    "    plt.ylabel(\"Cross validation score \\n of number of selected features\")\n",
    "    plt.plot(range(1, len(rfe.grid_scores_)+1), rfe.grid_scores_)\n",
    "    plt.show()\n",
    "\n",
    "    print('The optimal number of features is {}'.format(rfe.n_features_))\n",
    "    features = [f for f,s in zip(X.columns, rfe.support_) if s]\n",
    "    print('The selected features are:')\n",
    "    print ('{}'.format(features))\n",
    "    \n",
    "    for i in range(X.shape[1]):\n",
    "        print('Column: %d, Selected %s, Rank: %.3f' % (i, rfe.support_[i], rfe.ranking_[i]))\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 393 entries, 0 to 392\n",
      "Data columns (total 27 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   RTK_Num_All_Plots_Data  393 non-null    int64  \n",
      " 1   Plot_All_Plots_Data     393 non-null    object \n",
      " 2   Site_Name               393 non-null    object \n",
      " 3   min                     393 non-null    float64\n",
      " 4   prctile5                393 non-null    float64\n",
      " 5   prctile95               393 non-null    float64\n",
      " 6   std                     393 non-null    float64\n",
      " 7   MTD                     393 non-null    float64\n",
      " 8   median                  393 non-null    float64\n",
      " 9   skewness                393 non-null    float64\n",
      " 10  IQR                     393 non-null    float64\n",
      " 11  meanci_1                393 non-null    float64\n",
      " 12  meanci_2                393 non-null    float64\n",
      " 13  Diff_median_of_plot     393 non-null    float64\n",
      " 14  Diff_std_of_plot        393 non-null    float64\n",
      " 15  Diff_mean_of_row        393 non-null    float64\n",
      " 16  Diff_std_of_row         393 non-null    float64\n",
      " 17  prctile33               393 non-null    float64\n",
      " 18  median_first_ring       393 non-null    float64\n",
      " 19  median_second_ring      393 non-null    float64\n",
      " 20  median_third_ring       393 non-null    float64\n",
      " 21  median_core             393 non-null    float64\n",
      " 22  CWSI                    393 non-null    float64\n",
      " 23  CWSI_minus_CWSI_of_row  393 non-null    float64\n",
      " 24  Type                    393 non-null    object \n",
      " 25  SWP                     369 non-null    float64\n",
      " 26  Y                       393 non-null    int64  \n",
      "dtypes: float64(22), int64(2), object(3)\n",
      "memory usage: 83.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_Lavi_Kedma = pd.read_excel(os.path.join(os.getcwd(), 'data_Kedma&Lavi_afer_DataPreparation.xlsx')).iloc[: , 1:] \n",
    "df_Lavi_Kedma.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Lavi_Kedma['Type']=df_Lavi_Kedma['Type'].astype('category')\n",
    "\n",
    "data_train = df_Lavi_Kedma[df_Lavi_Kedma.Site_Name=='Kedma'].copy(True)\n",
    "data_labels_train = data_train[['Type']]\n",
    "\n",
    "data_test = df_Lavi_Kedma[df_Lavi_Kedma.Site_Name=='Lavi'].copy(True)\n",
    "data_labels_test = data_test['Type']\n",
    "\n",
    "vars_to_drop = [\"RTK_Num_All_Plots_Data\",'Plot_All_Plots_Data','Site_Name','SWP','Type','Y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive featue elimination - cross validation based on RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting features using RFECV with RF and score F2score - as FN (miss malfunction is more important)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Y as categorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 189 entries, 204 to 392\n",
      "Data columns (total 21 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   min                     189 non-null    float64\n",
      " 1   prctile5                189 non-null    float64\n",
      " 2   prctile95               189 non-null    float64\n",
      " 3   std                     189 non-null    float64\n",
      " 4   MTD                     189 non-null    float64\n",
      " 5   median                  189 non-null    float64\n",
      " 6   skewness                189 non-null    float64\n",
      " 7   IQR                     189 non-null    float64\n",
      " 8   meanci_1                189 non-null    float64\n",
      " 9   meanci_2                189 non-null    float64\n",
      " 10  Diff_median_of_plot     189 non-null    float64\n",
      " 11  Diff_std_of_plot        189 non-null    float64\n",
      " 12  Diff_mean_of_row        189 non-null    float64\n",
      " 13  Diff_std_of_row         189 non-null    float64\n",
      " 14  prctile33               189 non-null    float64\n",
      " 15  median_first_ring       189 non-null    float64\n",
      " 16  median_second_ring      189 non-null    float64\n",
      " 17  median_third_ring       189 non-null    float64\n",
      " 18  median_core             189 non-null    float64\n",
      " 19  CWSI                    189 non-null    float64\n",
      " 20  CWSI_minus_CWSI_of_row  189 non-null    float64\n",
      "dtypes: float64(21)\n",
      "memory usage: 32.5 KB\n"
     ]
    }
   ],
   "source": [
    "data_labels_train\n",
    "data_train.drop(vars_to_drop,axis=1).info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)\n",
    "# features = RFECV_Random_Forest(data_train.drop(vars_to_drop,axis=1),data_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['min', 'prctile5', 'prctile95', 'std', 'MTD', 'median', 'skewness', 'IQR', 'meanci_1', 'Diff_median_of_plot', 'Diff_std_of_plot', 'Diff_mean_of_row', 'Diff_std_of_row', 'prctile33', 'median_first_ring', 'median_second_ring', 'median_core', 'CWSI', 'CWSI_minus_CWSI_of_row']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train[features]\n",
    "data_labels_train =data_labels_train['Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN\n",
      "73\n",
      "Created\n",
      "KNN _results_summary was created\n"
     ]
    }
   ],
   "source": [
    "ml_results,best_models,metrics_results = conduct_tunning_and_classification_for_each_family_model_CV(data_train[features],\n",
    "                                                                                                     data_labels_train,\n",
    "                                                                                                     stage='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Algorithm</th>\n",
       "      <th>DT</th>\n",
       "      <th>RF</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>KNN</th>\n",
       "      <th>svm_linear</th>\n",
       "      <th>svm_rbf</th>\n",
       "      <th>svm_poly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_index</th>\n",
       "      <td>20</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCC</th>\n",
       "      <td>0.162229</td>\n",
       "      <td>0.283351</td>\n",
       "      <td>0.105837</td>\n",
       "      <td>0.302345</td>\n",
       "      <td>0.085634</td>\n",
       "      <td>0.208864</td>\n",
       "      <td>0.229525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACC</th>\n",
       "      <td>0.636188</td>\n",
       "      <td>0.691181</td>\n",
       "      <td>0.658236</td>\n",
       "      <td>0.690185</td>\n",
       "      <td>0.633826</td>\n",
       "      <td>0.655164</td>\n",
       "      <td>0.539772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1score</th>\n",
       "      <td>0.731371</td>\n",
       "      <td>0.774937</td>\n",
       "      <td>0.772957</td>\n",
       "      <td>0.767972</td>\n",
       "      <td>0.7475</td>\n",
       "      <td>0.745714</td>\n",
       "      <td>0.545343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F2score</th>\n",
       "      <td>0.734796</td>\n",
       "      <td>0.779582</td>\n",
       "      <td>0.821671</td>\n",
       "      <td>0.760022</td>\n",
       "      <td>0.776649</td>\n",
       "      <td>0.745335</td>\n",
       "      <td>0.453521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FNR</th>\n",
       "      <td>0.26191</td>\n",
       "      <td>0.2168</td>\n",
       "      <td>0.14117</td>\n",
       "      <td>0.24455</td>\n",
       "      <td>0.20178</td>\n",
       "      <td>0.25385</td>\n",
       "      <td>0.59194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FPR</th>\n",
       "      <td>0.58333</td>\n",
       "      <td>0.50667</td>\n",
       "      <td>0.77333</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.17667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FNR_Leak</th>\n",
       "      <td>0.33538</td>\n",
       "      <td>0.27795</td>\n",
       "      <td>0.14385</td>\n",
       "      <td>0.34513</td>\n",
       "      <td>0.2041</td>\n",
       "      <td>0.31487</td>\n",
       "      <td>0.6059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FNR_Clog</th>\n",
       "      <td>0.19077</td>\n",
       "      <td>0.15692</td>\n",
       "      <td>0.13846</td>\n",
       "      <td>0.14462</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.19385</td>\n",
       "      <td>0.57846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FPR_Leak</th>\n",
       "      <td>0.1424</td>\n",
       "      <td>0.1456</td>\n",
       "      <td>0.1968</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.2016</td>\n",
       "      <td>0.1488</td>\n",
       "      <td>0.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FPR_Clog</th>\n",
       "      <td>0.13847</td>\n",
       "      <td>0.0982</td>\n",
       "      <td>0.17573</td>\n",
       "      <td>0.12053</td>\n",
       "      <td>0.14493</td>\n",
       "      <td>0.1112</td>\n",
       "      <td>0.03707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_ACC</th>\n",
       "      <td>0.57738</td>\n",
       "      <td>0.63827</td>\n",
       "      <td>0.54275</td>\n",
       "      <td>0.65272</td>\n",
       "      <td>0.53911</td>\n",
       "      <td>0.60308</td>\n",
       "      <td>0.6157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCC_multiclass</th>\n",
       "      <td>0.45935</td>\n",
       "      <td>0.54065</td>\n",
       "      <td>0.50515</td>\n",
       "      <td>0.54046</td>\n",
       "      <td>0.45958</td>\n",
       "      <td>0.48843</td>\n",
       "      <td>0.37262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Algorithm             DT        RF Naive Bayes       KNN svm_linear   svm_rbf  \\\n",
       "model_index           20        39           2        73          2        12   \n",
       "MCC             0.162229  0.283351    0.105837  0.302345   0.085634  0.208864   \n",
       "ACC             0.636188  0.691181    0.658236  0.690185   0.633826  0.655164   \n",
       "F1score         0.731371  0.774937    0.772957  0.767972     0.7475  0.745714   \n",
       "F2score         0.734796  0.779582    0.821671  0.760022   0.776649  0.745335   \n",
       "FNR              0.26191    0.2168     0.14117   0.24455    0.20178   0.25385   \n",
       "FPR              0.58333   0.50667     0.77333      0.45       0.72      0.54   \n",
       "FNR_Leak         0.33538   0.27795     0.14385   0.34513     0.2041   0.31487   \n",
       "FNR_Clog         0.19077   0.15692     0.13846   0.14462        0.2   0.19385   \n",
       "FPR_Leak          0.1424    0.1456      0.1968     0.096     0.2016    0.1488   \n",
       "FPR_Clog         0.13847    0.0982     0.17573   0.12053    0.14493    0.1112   \n",
       "balanced_ACC     0.57738   0.63827     0.54275   0.65272    0.53911   0.60308   \n",
       "MCC_multiclass   0.45935   0.54065     0.50515   0.54046    0.45958   0.48843   \n",
       "\n",
       "Algorithm       svm_poly  \n",
       "model_index           15  \n",
       "MCC             0.229525  \n",
       "ACC             0.539772  \n",
       "F1score         0.545343  \n",
       "F2score         0.453521  \n",
       "FNR              0.59194  \n",
       "FPR              0.17667  \n",
       "FNR_Leak          0.6059  \n",
       "FNR_Clog         0.57846  \n",
       "FPR_Leak           0.048  \n",
       "FPR_Clog         0.03707  \n",
       "balanced_ACC      0.6157  \n",
       "MCC_multiclass   0.37262  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models#.sort_values(by=[metric_to_optimize],ascending=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving folds results for T-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_neighbors': 10, 'weights': 'uniform', 'Algorithm': 'auto'}\n",
    "\n",
    "model_index = 73\n",
    "results_summary = pd.DataFrame(columns=['Algorithm','model_index', 'parameters',\n",
    "                                           'FNR','FPR','MCC','ACC','F1score','F2score'])\n",
    "data = data_train[features]\n",
    "data_labels =data_labels_train\n",
    "\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=10,weights='uniform',algorithm='auto')  # create classifier\n",
    "    \n",
    "Fold_num, MCC_results,F1score_results,F2score_results,FPR_results = [],[],[],[],[]               \n",
    "fold =1\n",
    "random.seed(10)\n",
    "skf = RepeatedStratifiedKFold(n_splits=5,n_repeats=5, random_state=12)\n",
    "    # K_folds:\n",
    "for train_index, test_index in skf.split(data, data_labels):\n",
    "    x_train_fold, x_test_fold = data.iloc[train_index], data.iloc[test_index]\n",
    "    y_train_fold, y_test_fold = data_labels.iloc[train_index], data_labels.iloc[test_index]\n",
    "    if (Algorithm not in ['RF','DT']):\n",
    "        if (Algorithm in('Naive Bayes','svm_linear')):\n",
    "            scaler = MinMaxScaler()\n",
    "        else:\n",
    "            scaler = StandardScaler()\n",
    "        x_train_fold = scaler.fit_transform(x_train_fold)\n",
    "        x_test_fold = scaler.fit_transform(x_test_fold)\n",
    "    classifier.fit(x_train_fold, y_train_fold.values.ravel())\n",
    "    y_prediction = classifier.predict(x_test_fold)\n",
    "    metrics_results = calculate_metrics(Algorithm,y_test_fold,y_prediction,metrics_results)\n",
    "    Fold_num.append(fold)\n",
    "    MCC_results.append(metrics_results['MCC'][Algorithm])\n",
    "    FPR_results.append(metrics_results['FPR'][Algorithm])\n",
    "    F1score_results.append(metrics_results['F1score'][Algorithm])\n",
    "    F2score_results.append(metrics_results['F2score'][Algorithm])\n",
    "    fold =fold+1\n",
    "balanced_ACC_results = pd.DataFrame(d['balanced_ACC'] for d in FPR_results).values.ravel()\n",
    "balanced_ACC_results\n",
    "\n",
    "results_summary= pd.DataFrame(data={'Algorithm':Algorithm,\n",
    "                                              'Fold_number':Fold_num,\n",
    "                                              'MCC': MCC_results,\n",
    "                                               'balanced_ACC':balanced_ACC_results,\n",
    "                                              'F1score': F1score_results,\n",
    "                                              'F2score': F2score_results})\n",
    "results_summary =results_summary.set_index('Fold_number')\n",
    "results_summary\n",
    "\n",
    "results_summary.to_csv(folder_path+Algorithm+'_folds_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating model performence on independent data set (Lavi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set  = df_Lavi_Kedma[df_Lavi_Kedma.Site_Name=='Lavi'].copy(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Control\n",
       "1         Leak\n",
       "2      Control\n",
       "3      Control\n",
       "4         Leak\n",
       "        ...   \n",
       "199       Leak\n",
       "200    Control\n",
       "201       Leak\n",
       "202       Leak\n",
       "203       Leak\n",
       "Name: Type, Length: 204, dtype: category\n",
       "Categories (3, object): ['Clog', 'Control', 'Leak']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_labels_test['Type']= test_set['Type'].astype('category').copy(True)\n",
    "data_test = test_set[features]\n",
    "data_labels_test['Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'B'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-120-fbf6ddc7594c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    697\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[1;31m# Reset internal state before fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m         \u001b[0mfirst_pass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'n_samples_seen_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 396\u001b[1;33m         X = self._validate_data(X, reset=first_pass,\n\u001b[0m\u001b[0;32m    397\u001b[0m                                 \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m                                 force_all_finite=\"allow-nan\")\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    419\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'no_validation'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    671\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 673\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    674\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order, like)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1897\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1898\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1899\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1900\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1901\u001b[0m     def __array_wrap__(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order, like)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'B'"
     ]
    }
   ],
   "source": [
    "results = init_metrics()\n",
    "Algorithm='SVM rbf'\n",
    "params = {\n",
    "          \"kernel\": \"rbf\",\n",
    "          \"c\": 0.1,\n",
    "          \"gamma\": 0.001\n",
    "        }\n",
    "    \n",
    "classifier=svm.SVC(probability=True,kernel=params['kernel'],C=params['c'],gamma=params['gamma'],max_iter=100000)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "x_train = scaler.fit_transform(data_train)\n",
    "x_test= scaler.fit_transform(data_test)\n",
    "\n",
    "classifier.fit(x_train, data_labels_train.values.ravel())\n",
    "y_prediction = classifier.predict(x_test)\n",
    "\n",
    "results = calculate_metrics(Algorithm,data_labels_test,y_prediction,results)\n",
    "\n",
    "results_summary = pd.DataFrame([[Algorithm,*list(params.values()),\n",
    "                                      results['FNR'][Algorithm], results['FPR'][Algorithm],\n",
    "                                     results['MCC'][Algorithm], results['ACC'][Algorithm],\n",
    "                                     results['F1score'][Algorithm], results['F2score'][Algorithm]]],\n",
    "            columns=['Algorithm',*list(params.keys()),'FNR','FPR', 'MCC', 'ACC','F1score','F2score'])\n",
    "\n",
    "results_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Y as ordinary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_Ordinary = pd.DataFrame(data_labels_train).copy(True)\n",
    "Y_Ordinary\n",
    "Y_Ordinary['Y'] = 0 \n",
    "Y_Ordinary.loc[Y_Ordinary['Type'] == 'Clog', 'Y'] = 0\n",
    "Y_Ordinary.loc[Y_Ordinary['Type'] == 'Control', 'Y'] = 1\n",
    "Y_Ordinary.loc[Y_Ordinary['Type'] == 'Leak', 'Y'] = 2\n",
    "\n",
    "Y_Ordinary_new= pd.Series(Y_Ordinary['Type'], dtype=\"category\")\n",
    "Y_Ordinary_new= Y_Ordinary_new.cat.codes\n",
    "X=data_train.drop(vars_to_drop,axis=1)\n",
    "y=Y_Ordinary_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mord'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-bc389cdbe1fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatthews_corrcoef\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmord\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfbeta_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmake_scorer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mord'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(10)\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "import sklearn.metrics as m\n",
    "import mord as mor\n",
    "\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "ftwo_scorer = make_scorer(fbeta_score, beta=2, average='weighted')\n",
    "\n",
    "average='weighted'\n",
    "# Automatically select the number of features for RFE\n",
    "# create pipeline\n",
    "rfe = RFECV(estimator= mor.LogisticIT())\n",
    "\n",
    "model =mor.LogisticIT()\n",
    "pipeline = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "# evaluate model\n",
    "cv = RepeatedStratifiedKFold(n_splits=5,n_repeats=5, random_state=12)\n",
    "\n",
    "n_scores = cross_val_score(pipeline, X, y, scoring=ftwo_scorer, cv=cv, n_jobs=-1, error_score='raise')\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "rfe.fit(X, y)\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score \\n of number of selected features\")\n",
    "plt.plot(range(1, len(rfe.grid_scores_)+1), rfe.grid_scores_)\n",
    "plt.show()\n",
    "\n",
    "print('The optimal number of features is {}'.format(rfe.n_features_))\n",
    "features2 = [f for f,s in zip(X.columns, rfe.support_) if s]\n",
    "print('The selected features are:')\n",
    "print ('{}'.format(features2))\n",
    "\n",
    "for i in range(X.shape[1]):\n",
    "    print('Column: %d, Selected %s, Rank: %.3f' % (i, rfe.support_[i], rfe.ranking_[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diff_std_of_row</th>\n",
       "      <th>CWSI_minus_CWSI_of_row</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>-0.020616</td>\n",
       "      <td>0.277926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>-0.389405</td>\n",
       "      <td>0.255195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.068012</td>\n",
       "      <td>0.179078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0.091777</td>\n",
       "      <td>0.170073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>0.198757</td>\n",
       "      <td>0.037510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>0.353332</td>\n",
       "      <td>-0.110986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>-0.411500</td>\n",
       "      <td>0.372105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>0.105174</td>\n",
       "      <td>-0.194867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>0.193455</td>\n",
       "      <td>-0.057650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>-0.142687</td>\n",
       "      <td>0.366748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Diff_std_of_row  CWSI_minus_CWSI_of_row\n",
       "204        -0.020616                0.277926\n",
       "205        -0.389405                0.255195\n",
       "206         0.068012                0.179078\n",
       "207         0.091777                0.170073\n",
       "208         0.198757                0.037510\n",
       "..               ...                     ...\n",
       "388         0.353332               -0.110986\n",
       "389        -0.411500                0.372105\n",
       "390         0.105174               -0.194867\n",
       "391         0.193455               -0.057650\n",
       "392        -0.142687                0.366748\n",
       "\n",
       "[189 rows x 2 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features2 = ['Diff_std_of_row', 'CWSI_minus_CWSI_of_row']\n",
    "data_train2=data_train[features2].copy(True)\n",
    "data_train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree\n",
      "DT _results_summary was created\n",
      "RandomForest\n",
      "RF _results_summary was created\n",
      "NaiveBayes\n",
      "Naive Bayes _results_summary was created\n",
      "KNN\n",
      "KNN _results_summary was created\n",
      "svm_linear\n",
      "svm_linear _results_summary was created\n",
      "svm_rbf\n",
      "svm_rbf _results_summary was created\n",
      "svm_poly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\noy\\Anaconda3\\envs\\seaversioneleven\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_poly _results_summary was created\n"
     ]
    }
   ],
   "source": [
    "ml_results,best_models,metrics_results = conduct_tunning_and_classification_for_each_family_model_CV(data_train2,\n",
    "                                                                                                     data_labels_train,\n",
    "                                                                                                     stage='\\\\Features_of_Y_as_ordinary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Algorithm</th>\n",
       "      <th>DT</th>\n",
       "      <th>RF</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>KNN</th>\n",
       "      <th>svm_linear</th>\n",
       "      <th>svm_rbf</th>\n",
       "      <th>svm_poly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_index</th>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCC</th>\n",
       "      <td>0.155159</td>\n",
       "      <td>0.1986</td>\n",
       "      <td>0.105998</td>\n",
       "      <td>0.142241</td>\n",
       "      <td>0.122508</td>\n",
       "      <td>0.209649</td>\n",
       "      <td>0.26337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACC</th>\n",
       "      <td>0.626686</td>\n",
       "      <td>0.638179</td>\n",
       "      <td>0.630612</td>\n",
       "      <td>0.625405</td>\n",
       "      <td>0.644324</td>\n",
       "      <td>0.63909</td>\n",
       "      <td>0.601422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1score</th>\n",
       "      <td>0.719745</td>\n",
       "      <td>0.724251</td>\n",
       "      <td>0.739265</td>\n",
       "      <td>0.723228</td>\n",
       "      <td>0.753658</td>\n",
       "      <td>0.722206</td>\n",
       "      <td>0.645802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F2score</th>\n",
       "      <td>0.713468</td>\n",
       "      <td>0.711499</td>\n",
       "      <td>0.75819</td>\n",
       "      <td>0.719714</td>\n",
       "      <td>0.781258</td>\n",
       "      <td>0.704018</td>\n",
       "      <td>0.574139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FNR</th>\n",
       "      <td>0.28923</td>\n",
       "      <td>0.29557</td>\n",
       "      <td>0.22794</td>\n",
       "      <td>0.28215</td>\n",
       "      <td>0.19852</td>\n",
       "      <td>0.30665</td>\n",
       "      <td>0.46486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FPR</th>\n",
       "      <td>0.55333</td>\n",
       "      <td>0.50333</td>\n",
       "      <td>0.67333</td>\n",
       "      <td>0.57333</td>\n",
       "      <td>0.69333</td>\n",
       "      <td>0.47667</td>\n",
       "      <td>0.25667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FNR_Leak</th>\n",
       "      <td>0.33308</td>\n",
       "      <td>0.32436</td>\n",
       "      <td>0.22179</td>\n",
       "      <td>0.33154</td>\n",
       "      <td>0.17513</td>\n",
       "      <td>0.29641</td>\n",
       "      <td>0.52385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FNR_Clog</th>\n",
       "      <td>0.24615</td>\n",
       "      <td>0.26769</td>\n",
       "      <td>0.23385</td>\n",
       "      <td>0.23385</td>\n",
       "      <td>0.22154</td>\n",
       "      <td>0.31692</td>\n",
       "      <td>0.40615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FPR_Leak</th>\n",
       "      <td>0.1616</td>\n",
       "      <td>0.1824</td>\n",
       "      <td>0.1984</td>\n",
       "      <td>0.1584</td>\n",
       "      <td>0.2144</td>\n",
       "      <td>0.1632</td>\n",
       "      <td>0.0848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FPR_Clog</th>\n",
       "      <td>0.10473</td>\n",
       "      <td>0.05967</td>\n",
       "      <td>0.12573</td>\n",
       "      <td>0.11747</td>\n",
       "      <td>0.11927</td>\n",
       "      <td>0.06607</td>\n",
       "      <td>0.03847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_ACC</th>\n",
       "      <td>0.57872</td>\n",
       "      <td>0.60055</td>\n",
       "      <td>0.54936</td>\n",
       "      <td>0.57226</td>\n",
       "      <td>0.55407</td>\n",
       "      <td>0.60834</td>\n",
       "      <td>0.63924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCC_multiclass</th>\n",
       "      <td>0.44673</td>\n",
       "      <td>0.4655</td>\n",
       "      <td>0.45275</td>\n",
       "      <td>0.44192</td>\n",
       "      <td>0.47527</td>\n",
       "      <td>0.46752</td>\n",
       "      <td>0.43757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Algorithm             DT        RF Naive Bayes       KNN svm_linear   svm_rbf  \\\n",
       "model_index           10        19           1        73          2        28   \n",
       "MCC             0.155159    0.1986    0.105998  0.142241   0.122508  0.209649   \n",
       "ACC             0.626686  0.638179    0.630612  0.625405   0.644324   0.63909   \n",
       "F1score         0.719745  0.724251    0.739265  0.723228   0.753658  0.722206   \n",
       "F2score         0.713468  0.711499     0.75819  0.719714   0.781258  0.704018   \n",
       "FNR              0.28923   0.29557     0.22794   0.28215    0.19852   0.30665   \n",
       "FPR              0.55333   0.50333     0.67333   0.57333    0.69333   0.47667   \n",
       "FNR_Leak         0.33308   0.32436     0.22179   0.33154    0.17513   0.29641   \n",
       "FNR_Clog         0.24615   0.26769     0.23385   0.23385    0.22154   0.31692   \n",
       "FPR_Leak          0.1616    0.1824      0.1984    0.1584     0.2144    0.1632   \n",
       "FPR_Clog         0.10473   0.05967     0.12573   0.11747    0.11927   0.06607   \n",
       "balanced_ACC     0.57872   0.60055     0.54936   0.57226    0.55407   0.60834   \n",
       "MCC_multiclass   0.44673    0.4655     0.45275   0.44192    0.47527   0.46752   \n",
       "\n",
       "Algorithm       svm_poly  \n",
       "model_index           77  \n",
       "MCC              0.26337  \n",
       "ACC             0.601422  \n",
       "F1score         0.645802  \n",
       "F2score         0.574139  \n",
       "FNR              0.46486  \n",
       "FPR              0.25667  \n",
       "FNR_Leak         0.52385  \n",
       "FNR_Clog         0.40615  \n",
       "FPR_Leak          0.0848  \n",
       "FPR_Clog         0.03847  \n",
       "balanced_ACC     0.63924  \n",
       "MCC_multiclass   0.43757  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models#.sort_values(by=['F2score'],ascending=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating model performence on independent data set (Lavi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MTD</th>\n",
       "      <th>Meanci_1</th>\n",
       "      <th>Diff_median_of_plot</th>\n",
       "      <th>Diff_mean_of_row</th>\n",
       "      <th>Diff_std_of_row</th>\n",
       "      <th>median_second_ring</th>\n",
       "      <th>CWSI</th>\n",
       "      <th>CWSI_minus_CWSI_of_row</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.857778</td>\n",
       "      <td>3.180862</td>\n",
       "      <td>-1.293726</td>\n",
       "      <td>-1.275677</td>\n",
       "      <td>0.687112</td>\n",
       "      <td>2.991489</td>\n",
       "      <td>0.537787</td>\n",
       "      <td>-0.320373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.267117</td>\n",
       "      <td>4.857138</td>\n",
       "      <td>-1.413829</td>\n",
       "      <td>-1.292092</td>\n",
       "      <td>0.497600</td>\n",
       "      <td>3.774675</td>\n",
       "      <td>0.617892</td>\n",
       "      <td>-0.234274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.295044</td>\n",
       "      <td>2.880736</td>\n",
       "      <td>-0.966367</td>\n",
       "      <td>-0.964791</td>\n",
       "      <td>0.558871</td>\n",
       "      <td>2.636387</td>\n",
       "      <td>0.441409</td>\n",
       "      <td>-0.223995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.695513</td>\n",
       "      <td>2.661326</td>\n",
       "      <td>-0.702693</td>\n",
       "      <td>-0.979400</td>\n",
       "      <td>0.629056</td>\n",
       "      <td>2.423534</td>\n",
       "      <td>0.388723</td>\n",
       "      <td>-0.213326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.044307</td>\n",
       "      <td>4.111615</td>\n",
       "      <td>-0.962213</td>\n",
       "      <td>-1.359424</td>\n",
       "      <td>0.274137</td>\n",
       "      <td>3.275674</td>\n",
       "      <td>0.483383</td>\n",
       "      <td>-0.210300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MTD  Meanci_1  Diff_median_of_plot  Diff_mean_of_row  \\\n",
       "0   1.857778  3.180862            -1.293726         -1.275677   \n",
       "1   9.267117  4.857138            -1.413829         -1.292092   \n",
       "2   2.295044  2.880736            -0.966367         -0.964791   \n",
       "3   2.695513  2.661326            -0.702693         -0.979400   \n",
       "4  10.044307  4.111615            -0.962213         -1.359424   \n",
       "\n",
       "   Diff_std_of_row  median_second_ring      CWSI  CWSI_minus_CWSI_of_row  \n",
       "0         0.687112            2.991489  0.537787               -0.320373  \n",
       "1         0.497600            3.774675  0.617892               -0.234274  \n",
       "2         0.558871            2.636387  0.441409               -0.223995  \n",
       "3         0.629056            2.423534  0.388723               -0.213326  \n",
       "4         0.274137            3.275674  0.483383               -0.210300  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test2=test_set[features2].copy(True)\n",
    "data_test2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2 = init_metrics()\n",
    "{'kernel': 'rbf', 'C': 100, 'gamma': 0.1}\n",
    "\n",
    "Algorithm='SVM rbf'\n",
    "params = {\n",
    "          \"kernel\": \"rbf\",\n",
    "          \"c\": 0.1,\n",
    "          \"gamma\": 0.001\n",
    "        }\n",
    "    \n",
    "classifier=svm.SVC(probability=True,kernel=params['kernel'],C=params['c'],gamma=params['gamma'],max_iter=100000)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "x_train2 = scaler.fit_transform(data_train2)\n",
    "x_test2= scaler.fit_transform(data_test2)\n",
    "\n",
    "classifier.fit(x_train2,data_labels_train2.values.ravel())\n",
    "y_prediction2 = classifier.predict(x_test2)\n",
    "\n",
    "results2 = calculate_metrics(Algorithm,data_labels_test2,y_prediction2,results2)\n",
    "\n",
    "results_summary = pd.DataFrame([[Algorithm,*list(params.values()),\n",
    "                                      results2['FNR'][Algorithm], results2['FPR'][Algorithm],\n",
    "                                     results2['MCC'][Algorithm], results2['ACC'][Algorithm],\n",
    "                                     results2['F1score'][Algorithm], results2['F2score'][Algorithm]]],\n",
    "            columns=['Algorithm',*list(params.keys()),'FNR','FPR', 'MCC', 'ACC','F1score','F2score'])\n",
    "\n",
    "results_summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
